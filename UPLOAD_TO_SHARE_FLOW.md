# ðŸ“Š Upload â†’ Chunks â†’ Share Linking Analysis

## ðŸ”„ COMPLETE DATA FLOW

### Phase 1: File Upload â†’ Chunks Creation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. FILE UPLOAD                                               â”‚
â”‚    POST /api/offers/upload                                   â”‚
â”‚    (backend/api/routes/offers_upload.py:68)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CREATE/RESOLVE BATCH                                      â”‚
â”‚    _resolve_or_create_batch()                                â”‚
â”‚    â†’ Creates offer_batches row with token (bt_xxx)           â”‚
â”‚    â†’ Returns: batch_id, batch_token                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. SAVE FILE TO DISK                                         â”‚
â”‚    Path: /storage/offers/{batch_token}/{filename}           â”‚
â”‚    Safe filename applied                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. INSERT offer_files RECORD                                 â”‚
â”‚    INSERT INTO public.offer_files                            â”‚
â”‚    (filename, storage_path, batch_id, org_id, ...)           â”‚
â”‚    RETURNING id  â† file_id                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. CHUNK CREATION (_reembed_file)                            â”‚
â”‚    a) Read PDF from storage_path                             â”‚
â”‚    b) Extract text (PyPDF)                                   â”‚
â”‚    c) Split into chunks (1000 chars, 200 overlap)            â”‚
â”‚    d) DELETE FROM offer_chunks WHERE file_id = ?             â”‚
â”‚    e) INSERT chunks into offer_chunks                        â”‚
â”‚       - file_id (FK to offer_files)                          â”‚
â”‚       - chunk_index                                          â”‚
â”‚       - text                                                 â”‚
â”‚       - metadata {chunk_index, start_pos, end_pos, length}   â”‚
â”‚    f) UPDATE offer_files SET embeddings_ready = true         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
                 âœ… SUCCESS
    Chunks linked: offer_chunks.file_id â†’ offer_files.id
                   offer_files.batch_id â†’ offer_batches.id
```

### Phase 2: Share Creation â†’ Batch Token Linking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CREATE SHARE                                              â”‚
â”‚    POST /shares                                              â”‚
â”‚    Body: { document_ids: ["uuid::1::file.pdf", ...] }       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. INFER BATCH TOKEN                                         â”‚
â”‚    _infer_batch_token_via_doc_ids(document_ids)              â”‚
â”‚    (app/main.py:1078)                                        â”‚
â”‚                                                              â”‚
â”‚    Logic:                                                    â”‚
â”‚    a) Extract filename from doc_id: "uuid::idx::FILE.pdf"   â”‚
â”‚    b) Apply _safe_filename() to normalize                   â”‚
â”‚    c) Query:                                                 â”‚
â”‚       SELECT ob.token, COUNT(*) as match_count              â”‚
â”‚       FROM offer_files of                                    â”‚
â”‚       JOIN offer_batches ob ON ob.id = of.batch_id          â”‚
â”‚       WHERE of.filename = ANY(filenames_array)              â”‚
â”‚       GROUP BY ob.token                                      â”‚
â”‚       ORDER BY match_count DESC                             â”‚
â”‚       LIMIT 1                                                â”‚
â”‚                                                              â”‚
â”‚    â†’ Returns: batch_token (or NULL if no match)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CREATE SHARE RECORD                                       â”‚
â”‚    INSERT INTO share_links                                   â”‚
â”‚    payload: {                                                â”‚
â”‚      batch_token: "bt_xxx"  â† From inference                â”‚
â”‚      document_ids: [...]                                     â”‚
â”‚      mode: "by-documents"                                    â”‚
â”‚    }                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 3: Ask-Share Query â†’ Chunks Retrieval

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ASK-SHARE REQUEST                                         â”‚
â”‚    POST /api/qa/ask-share                                    â”‚
â”‚    Body: { share_token: "...", question: "..." }            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. LOAD SHARE RECORD                                         â”‚
â”‚    _load_share_record(share_token)                           â”‚
â”‚    â†’ Returns: { payload: { batch_token, document_ids } }    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. GET ORG_ID & BATCH_TOKEN                                  â”‚
â”‚    org_id = share.org_id                                     â”‚
â”‚    batch_token = share.payload.batch_token                   â”‚
â”‚                                                              â”‚
â”‚    IF batch_token is NULL:                                   â”‚
â”‚      â†’ infer_batch_token_for_docs(document_ids, org_id)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. QUERY CHUNKS (_select_offer_chunks_from_db)              â”‚
â”‚    (backend/api/routes/qa.py:29)                             â”‚
â”‚                                                              â”‚
â”‚    IF batch_token exists:                                    â”‚
â”‚      SELECT oc.file_id, of.filename, oc.chunk_index,        â”‚
â”‚             oc.text, of.insurer_code                         â”‚
â”‚      FROM offer_chunks oc                                    â”‚
â”‚      JOIN offer_files of ON of.id = oc.file_id              â”‚
â”‚      JOIN offer_batches ob ON ob.id = of.batch_id           â”‚
â”‚      WHERE ob.token = %batch_token%                          â”‚
â”‚        AND ob.org_id = %org_id%                              â”‚
â”‚                                                              â”‚
â”‚    ELSE (fallback to document_ids):                          â”‚
â”‚      SELECT ... FROM offer_chunks oc                         â”‚
â”‚      JOIN offer_files of ON of.id = oc.file_id              â”‚
â”‚      WHERE of.org_id = %org_id%                              â”‚
â”‚        AND of.filename = ANY(%document_ids%)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. RESULT CHECK                                              â”‚
â”‚    IF rows.length == 0:                                      â”‚
â”‚      â†’ HTTPException(404, "No offer chunks available")       â”‚
â”‚    ELSE:                                                     â”‚
â”‚      â†’ Embed question, rank chunks, generate answer          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ” CRITICAL LINKING POINTS

### âœ… Point 1: File Upload â†’ Chunks (Direct Link)
```sql
offer_chunks.file_id â†’ offer_files.id
```
**Created by:** `_reembed_file()` during upload  
**Always works** if reembed succeeds

### âš ï¸ Point 2: Share â†’ Batch Token (Inference)
```sql
document_ids â†’ filename matching â†’ offer_files.filename
                                    â†’ offer_files.batch_id
                                    â†’ offer_batches.token
```
**Created by:** `_infer_batch_token_via_doc_ids()`  
**CAN FAIL** if:
- Filename mismatch (doc_id has different name than offer_files.filename)
- No matching files in database
- Multiple batches, wrong one selected

### âš ï¸ Point 3: Ask-Share â†’ Chunks (Via Batch)
```sql
batch_token â†’ offer_batches.id
           â†’ offer_files.batch_id
           â†’ offer_chunks.file_id
```
**CAN FAIL** if:
- batch_token is NULL (inference failed)
- batch_token points to wrong batch
- org_id mismatch
- Chunks weren't created

---

## ðŸ› COMMON FAILURE MODES

### Failure 1: Filename Mismatch
**Symptom:** `total_chunks = 0` but files exist

```python
# Document ID from old upload:
doc_id = "abc123::1::Original File Name.pdf"

# After upload with safe_filename:
offer_files.filename = "Original_File_Name.pdf"

# Inference extracts:
extracted = "Original File Name.pdf"  # â† No match!
```

**Fix:** Use `_safe_filename()` during inference (already implemented in main.py:1092)

### Failure 2: Batch Token NULL in Share
**Symptom:** Share has `batch_token: null`, inference fails at query time

**Causes:**
- Share created before files uploaded
- document_ids don't match any offer_files
- Inference logic bug

**Debug:**
```sql
-- Check what's in share
SELECT payload->>'batch_token', payload->>'document_ids' 
FROM share_links 
WHERE token = 'SHARE_TOKEN';

-- Check what's in offer_files
SELECT filename, batch_id 
FROM offer_files 
WHERE org_id = X;
```

### Failure 3: Chunks Never Created
**Symptom:** `embeddings_ready = false`, chunk count = 0

**Causes:**
- Reembed failed during upload
- PDF text extraction failed
- File not found on disk

**Debug:**
```sql
-- Check embedding status
SELECT id, filename, embeddings_ready, storage_path
FROM offer_files
WHERE batch_id = (SELECT id FROM offer_batches WHERE token = 'BATCH_TOKEN');

-- Check chunk count
SELECT file_id, COUNT(*) 
FROM offer_chunks 
WHERE file_id IN (SELECT id FROM offer_files WHERE batch_id = X)
GROUP BY file_id;
```

### Failure 4: Wrong Batch Selected
**Symptom:** Query runs but returns empty (wrong org_id or batch)

**Cause:** Inference picks wrong batch when multiple batches have same filenames

**Debug:**
```sql
-- Find all batches with matching files
SELECT ob.token, ob.org_id, COUNT(*) as file_count
FROM offer_files of
JOIN offer_batches ob ON ob.id = of.batch_id
WHERE of.filename IN ('file1.pdf', 'file2.pdf')
GROUP BY ob.token, ob.org_id;
```

---

## ðŸ§ª DEBUGGING CHECKLIST

### Step 1: Check Share â†’ Batch Link
```bash
curl "https://gpt-vis.onrender.com/shares/SHARE_TOKEN" | jq '{
  batch_token: .payload.batch_token,
  document_ids: .payload.document_ids,
  org_id: .org_id
}'
```

**Expected:** `batch_token` should be a `bt_xxx` string, not null

### Step 2: Check Batch â†’ Files Link
```sql
-- Use batch_token from above
SELECT id, filename, embeddings_ready, storage_path
FROM offer_files
WHERE batch_id = (SELECT id FROM offer_batches WHERE token = 'bt_xxx')
ORDER BY id;
```

**Expected:** Multiple files, `embeddings_ready = true`

### Step 3: Check Files â†’ Chunks Link
```sql
-- Use file IDs from above
SELECT file_id, COUNT(*) as chunk_count
FROM offer_chunks
WHERE file_id IN (SELECT id FROM offer_files WHERE batch_id = X)
GROUP BY file_id;
```

**Expected:** Each file has > 0 chunks

### Step 4: Test Chunks Query Directly
```sql
-- This is what ask-share runs
SELECT oc.file_id, of.filename, oc.chunk_index, LEFT(oc.text, 100) as preview
FROM offer_chunks oc
JOIN offer_files of ON of.id = oc.file_id
JOIN offer_batches ob ON ob.id = of.batch_id
WHERE ob.token = 'bt_xxx'
  AND ob.org_id = 1
LIMIT 5;
```

**Expected:** Rows returned with text previews

---

## ðŸ©¹ FIXES

### Fix 1: Re-Infer Batch Token for Share
```sql
-- Get document IDs from share
SELECT payload->>'document_ids' FROM share_links WHERE token = 'SHARE_TOKEN';

-- Manually find correct batch
SELECT ob.token, COUNT(*) as matches
FROM offer_files of
JOIN offer_batches ob ON ob.id = of.batch_id
WHERE of.filename IN ('file1.pdf', 'file2.pdf')  -- From document_ids
GROUP BY ob.token
ORDER BY matches DESC
LIMIT 1;

-- Update share with correct batch_token
UPDATE share_links
SET payload = jsonb_set(payload, '{batch_token}', '"bt_correct_token"')
WHERE token = 'SHARE_TOKEN';
```

### Fix 2: Re-Embed Files
```bash
# For each file that has embeddings_ready = false
curl -X POST "https://gpt-vis.onrender.com/api/qa/reembed-file?file_id=FILE_ID" \
  -H "X-User-Role: admin"
```

### Fix 3: Recreate Share with Explicit Batch Token
```bash
curl -X POST "https://gpt-vis.onrender.com/shares" \
  -H "Content-Type: application/json" \
  -H "X-Org-Id: 1" \
  -H "X-User-Id: 1" \
  -d '{
    "batch_token": "bt_correct_token",
    "title": "Recreated Share",
    "editable": true
  }'
```

---

## ðŸ“‹ SUMMARY

### The Chain
```
Upload â†’ offer_files.batch_id â†’ offer_batches.token (STORED)
                                          â†“
Share.payload.batch_token (INFERRED from document_ids)
                                          â†“
Query JOINs: batch_token â†’ offer_batches â†’ offer_files â†’ offer_chunks
```

### Weak Points
1. **Filename matching** during batch_token inference
2. **Null batch_token** in share.payload
3. **Missing chunks** (reembed failures)
4. **Org_id mismatches**

### Key Fix
**Always provide `batch_token` explicitly when creating shares** if you know it, rather than relying on inference:

```json
{
  "batch_token": "bt_known_token",
  "document_ids": [...]
}
```

This bypasses the filename matching logic entirely.

